{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084920ac-d8fb-4944-b833-85e39b90d46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.tree import plot_tree\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from trustee import ClassificationTrustee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1a0ceb-822d-4d82-a558-ad691f366e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "pool_1_ips = {\n",
    "    '169.231.10.199', \n",
    "    '169.231.210.93', \n",
    "    '169.231.172.165',\n",
    "}\n",
    "\n",
    "pool_2_ips = {\n",
    "    '128.111.52.37',\n",
    "}\n",
    "\n",
    "pool_3_ips = {\n",
    "    '169.231.8.190',\n",
    "    '169.231.123.195',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df76d947-b460-4341-a8f3-56d124f8f502",
   "metadata": {},
   "source": [
    "Now we have 2 different attacks, let's create 2 datasets - where they're labelled together as an attack and where they are different attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ffa4f4-718b-4435-91ed-d8840574cac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_1 = pd.read_csv(f'campus_dataset_1.csv')\n",
    "dataset_1['Class'] = 0\n",
    "dataset_1.loc[dataset_1['Src IP'].isin(pool_1_ips), 'Class'] = 1\n",
    "dataset_1.loc[dataset_1['Src IP'].isin(pool_3_ips), 'Class'] = 2\n",
    "ttl_data_1 = pd.read_csv(f'campus_ttl_1.csv')\n",
    "dataset_1 = dataset_1.merge(ttl_data_1, on=\"Flow ID\", how='left')\n",
    "\n",
    "dataset_2 = pd.read_csv(f'campus_dataset_2.csv')\n",
    "dataset_2['Class'] = 0\n",
    "dataset_2.loc[dataset_2['Src IP'].isin(pool_2_ips), 'Class'] = 1\n",
    "dataset_2.loc[dataset_2['Src IP'].isin(pool_3_ips), 'Class'] = 2\n",
    "ttl_data_2 = pd.read_csv(f'campus_ttl_2.csv')\n",
    "dataset_2 = dataset_2.merge(ttl_data_2, on=\"Flow ID\", how='left')\n",
    "\n",
    "dataset = pd.concat([dataset_1, dataset_2])\n",
    "dataset = dataset.replace([np.inf, -np.inf], np.nan)\n",
    "dataset = dataset.dropna(axis=0)\n",
    "dataset = dataset.drop([\n",
    "    'Flow ID',\n",
    "    'Src IP',\n",
    "    'Dst IP',\n",
    "    'Timestamp', \n",
    "    'Protocol',    # always tcp\n",
    "    'Label',       # empty\n",
    "], axis=1)\n",
    "\n",
    "campus_dataset_separated = dataset\n",
    "campus_dataset_merged = dataset.copy()\n",
    "campus_dataset_merged.loc[campus_dataset_merged['Class'] == 2, 'Class'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9fccab-2526-4532-80f3-edd7a43532fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bbe2ff7-09c0-43a2-982a-4fbac5c60c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_variable = 'Class'\n",
    "features = list(sorted(set(campus_dataset_separated.columns) - {target_variable}))\n",
    "\n",
    "x_train_separated = campus_dataset_separated[features]\n",
    "y_train_separated = campus_dataset_separated[target_variable]\n",
    "\n",
    "x_train_merged = campus_dataset_merged[features]\n",
    "y_train_merged = campus_dataset_merged[target_variable]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4406d672-ce47-461b-83cb-b302385438c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers_merged = [\n",
    "    KNeighborsClassifier(2),\n",
    "    MLPClassifier(alpha=1, max_iter=100),\n",
    "    GradientBoostingClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    RandomForestClassifier(max_depth=2),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f89356-6852-4bd8-bf20-7c520da60626",
   "metadata": {},
   "source": [
    "## Explore merged attacks first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7af331-7157-429d-998d-4d4d440dfc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for clf in classifiers_merged:\n",
    "    print(clf)\n",
    "    clf.fit(x_train_merged, y_train_merged)\n",
    "    y_pred = clf.predict(x_train_merged)\n",
    "    print(\"campus dataset training accuracy: \")\n",
    "    print(metrics.classification_report(y_train_merged, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d803be-4608-4c2f-bf15-3069f71bb4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(x_train_merged, y_train_merged)\n",
    "y_pred = clf.predict(x_train_merged)\n",
    "print(metrics.classification_report(y_train_merged, y_pred))\n",
    "print(metrics.confusion_matrix(y_train_merged, y_pred))\n",
    "fig = plt.figure(figsize=(25,20))\n",
    "plot_tree(clf, feature_names=x_train_merged.columns, class_names=['benign', 'attack'], filled=True, max_depth=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7066398-c88c-4478-aa9d-58e539d44407",
   "metadata": {},
   "source": [
    "## Explore separated classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3068dfb2-55b6-468f-9941-b5c02b8e8e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers_separated = [\n",
    "    KNeighborsClassifier(3),\n",
    "    MLPClassifier(alpha=1, max_iter=100),\n",
    "    GradientBoostingClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    RandomForestClassifier(max_depth=2),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73dcecd-fdd9-42ba-b5ed-e4be3c66246e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for clf in classifiers_separated:\n",
    "    print(clf)\n",
    "    clf.fit(x_train_separated, y_train_separated)\n",
    "    y_pred = clf.predict(x_train_separated)\n",
    "    print(\"campus dataset training accuracy: \")\n",
    "    print(metrics.classification_report(y_train_separated, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f04217-6b01-4034-87cc-53640960b608",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(x_train_separated, y_train_separated)\n",
    "y_pred = clf.predict(x_train_separated)\n",
    "print(metrics.classification_report(y_train_separated, y_pred))\n",
    "print(metrics.confusion_matrix(y_train_separated, y_pred))\n",
    "fig = plt.figure(figsize=(25,20))\n",
    "plot_tree(clf, feature_names=x_train_separated.columns, class_names=['benign', 'attack_patator', 'attack_hydra'], filled=True, max_depth=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8efcddf-e0d3-4710-a1ca-323ad4d92b2e",
   "metadata": {},
   "source": [
    "## Previous OOD dataset exploration\n",
    "Let's take the OOD dataset from the previous experiment and check classifiers on it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4fd247-5448-46d6-8bcd-ef59ad478fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pool_ips = {\n",
    "    '169.231.10.199',\n",
    "    '169.231.210.93',\n",
    "    '169.231.8.190',\n",
    "    '169.231.123.195',\n",
    "}\n",
    "\n",
    "dataset = pd.read_csv(f'../0.3/ood_dataset.csv')\n",
    "dataset['Class'] = 0\n",
    "dataset.loc[dataset['Src IP'].isin(pool_ips), 'Class'] = 2\n",
    "ttl_data = pd.read_csv(f'../0.3/ood_ttl.csv')\n",
    "dataset = dataset.merge(ttl_data, on=\"Flow ID\", how='left')\n",
    "dataset = dataset.replace([np.inf, -np.inf], np.nan)\n",
    "dataset = dataset.dropna(axis=0)\n",
    "dataset = dataset.drop([\n",
    "    'Flow ID',\n",
    "    'Src IP',\n",
    "    'Dst IP',\n",
    "    'Timestamp', \n",
    "    'Protocol',    # always tcp\n",
    "    'Label',       # empty\n",
    "], axis=1)\n",
    "\n",
    "\n",
    "hydra_dataset_separated = dataset\n",
    "hydra_dataset_merged = dataset.copy()\n",
    "hydra_dataset_merged.loc[hydra_dataset_merged['Class'] == 2, 'Class'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540a065c-88b0-42fa-ba18-77edae7b7a2c",
   "metadata": {},
   "source": [
    "## Merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d73d4a-b309-44a1-8a6d-503c28b1de84",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = hydra_dataset_merged[features]\n",
    "y_test = hydra_dataset_merged[target_variable]\n",
    "for clf in classifiers_merged:\n",
    "    print(clf)\n",
    "    print(\"OOD test dataset accuracy: \")\n",
    "    y_pred = clf.predict(x_test)\n",
    "    print(metrics.classification_report(y_test, y_pred))\n",
    "    print(metrics.confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2a385b-a57f-4574-81ac-be5eb1afacee",
   "metadata": {},
   "source": [
    "## Separated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54407ba2-13cf-4a2b-bb21-696a0349e839",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = hydra_dataset_separated[features]\n",
    "y_test = hydra_dataset_separated[target_variable]\n",
    "for clf in classifiers_separated:\n",
    "    print(clf)\n",
    "    print(\"OOD test dataset accuracy: \")\n",
    "    y_pred = clf.predict(x_test)\n",
    "    print(metrics.classification_report(y_test, y_pred))\n",
    "    print(metrics.confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a32074d-f6d7-40e0-a1f6-b2578d4b7bcf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "netunicorn",
   "language": "python",
   "name": "netunicorn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
