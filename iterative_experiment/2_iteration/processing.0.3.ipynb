{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146ebbad-088c-4284-b641-a8cae527bc2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.tree import plot_tree\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from trustee import ClassificationTrustee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a725d89f-bc44-4d81-9f70-832f6722bea7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pool_1_ips = {\n",
    "    '169.231.8.190', \n",
    "    '169.231.123.195', \n",
    "    '169.231.10.199', \n",
    "    '169.231.210.93', \n",
    "    '169.231.172.165', \n",
    "}\n",
    "\n",
    "pool_2_ips = {\n",
    "    '128.111.52.37',\n",
    "    '169.231.107.236',\n",
    "    '169.231.111.168',\n",
    "    '169.231.90.61',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d86c0b9-2daa-4f17-a15c-ca8443d41135",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataset(prefix: str):\n",
    "    dataset_1 = pd.read_csv(f'{prefix}_dataset_1.csv')\n",
    "    dataset_1['Class'] = 0\n",
    "    dataset_1.loc[dataset_1['Src IP'].isin(pool_1_ips), 'Class'] = 1\n",
    "    ttl_data_1 = pd.read_csv(f'{prefix}_ttl_1.csv')\n",
    "    dataset_1 = dataset_1.merge(ttl_data_1, on=\"Flow ID\", how='left')\n",
    "    \n",
    "    dataset_2 = pd.read_csv(f'{prefix}_dataset_2.csv')\n",
    "    dataset_2['Class'] = 0\n",
    "    dataset_2.loc[dataset_2['Src IP'].isin(pool_2_ips), 'Class'] = 1\n",
    "    ttl_data_2 = pd.read_csv(f'{prefix}_ttl_2.csv')\n",
    "    dataset_2 = dataset_2.merge(ttl_data_2, on=\"Flow ID\", how='left')\n",
    "    \n",
    "    dataset = pd.concat([dataset_1, dataset_2])\n",
    "    dataset = dataset.replace([np.inf, -np.inf], np.nan)\n",
    "    dataset = dataset.dropna(axis=0)\n",
    "    dataset = dataset.drop([\n",
    "        'Flow ID',\n",
    "        'Src IP',\n",
    "        'Dst IP',\n",
    "        'Timestamp', \n",
    "        'Protocol',    # always tcp\n",
    "        'Label',       # empty\n",
    "    ], axis=1)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841391d7-e44a-4df3-9ec8-b246d7f156af",
   "metadata": {},
   "outputs": [],
   "source": [
    "campus_dataset = read_dataset('campus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b6c9a5-ada4-4abb-9623-422679145b11",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_and_visualize(dataset, clf, visualize_tree = False):\n",
    "    target_variable = 'Class'\n",
    "    features = list(sorted(set(dataset.columns) - {target_variable}))\n",
    "    x_data = dataset[features]\n",
    "    y_data = dataset[target_variable]\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.25)\n",
    "    \n",
    "    x_train = pd.DataFrame(StandardScaler().fit_transform(x_train), columns = x_train.columns)\n",
    "    x_test = pd.DataFrame(StandardScaler().fit_transform(x_test), columns = x_test.columns)\n",
    "    \n",
    "    trained_clf = clf.fit(x_train, y_train)\n",
    "    prediction = trained_clf.predict(x_test)\n",
    "    print(metrics.classification_report(y_test, prediction))\n",
    "    \n",
    "    trustee = ClassificationTrustee(expert=trained_clf)\n",
    "    trustee.fit(x_train, y_train, num_iter=10, num_stability_iter=3, samples_size=0.8)\n",
    "    \n",
    "    _, dt, _, score = trustee.explain()\n",
    "    print(f\"Training score of pruned DT: {score}\")\n",
    "    dt_y_pred = dt.predict(x_test)\n",
    "    \n",
    "    print(\"Model explanation global fidelity report:\")\n",
    "    print(metrics.classification_report(prediction, dt_y_pred))\n",
    "    print(\"Model explanation score report:\")\n",
    "    print(metrics.classification_report(y_test, dt_y_pred))\n",
    "    \n",
    "    fig = plt.figure(figsize=(25,20))\n",
    "    plot_tree(dt, feature_names=x_train.columns, class_names=['benign', 'attack'], filled=True, max_depth=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f584e4a-e94b-4fa3-ac04-466709e450ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "azure_dataset = read_dataset('azure')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744a7074-1ded-492d-b939-8e10d00f09f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pool_1_ips = {\n",
    "    '157.245.108.149', # netunicorn-digitalocean-1\n",
    "    '34.214.149.122',  # netunicorn-aws-1\n",
    "}\n",
    "\n",
    "pool_2_ips = {\n",
    "    \"52.43.47.231\",   # netunicorn-aws-2\n",
    "    \"15.164.100.10\",  # netunicorn-aws-3\n",
    "    \"170.64.144.63\",  # netunicorn-digitalocean-2\n",
    "}\n",
    "multicloud_dataset = read_dataset('multicloud')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9411c1c5-cc37-4bac-944f-bc5e76c8f338",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b8f476-4820-414a-a8ad-ee94175eefd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_variable = 'Class'\n",
    "features = list(sorted(set(campus_dataset.columns) - {target_variable}))\n",
    "x_train = campus_dataset[features]\n",
    "y_train = campus_dataset[target_variable]\n",
    "x_test = azure_dataset[features]\n",
    "y_test = azure_dataset[target_variable]\n",
    "x_test_2 = multicloud_dataset[features]\n",
    "y_test_2 = multicloud_dataset[target_variable]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a118b80-4bfb-4084-b5e7-0c38e443f33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pd.DataFrame(StandardScaler().fit_transform(x_train), columns = x_train.columns)\n",
    "x_test = pd.DataFrame(StandardScaler().fit_transform(x_test), columns = x_test.columns)\n",
    "x_test_2 = pd.DataFrame(StandardScaler().fit_transform(x_test_2), columns = x_test_2.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8713df12-5944-4722-802a-554cabd494c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "classifiers = [\n",
    "    # MLPClassifier(),\n",
    "    # GradientBoostingClassifier(),\n",
    "    RandomForestClassifier(max_depth=3)\n",
    "]\n",
    "for clf in classifiers:\n",
    "    print(clf)\n",
    "    clf.fit(x_train, y_train)\n",
    "    y_pred = clf.predict(x_train)\n",
    "    print(\"campus dataset training accuracy: \")\n",
    "    print(metrics.classification_report(y_train, y_pred))\n",
    "\n",
    "    print(\"Azure dataset test accuracy: \")\n",
    "    y_pred = clf.predict(x_test)\n",
    "    print(metrics.classification_report(y_test, y_pred))\n",
    "    print(metrics.confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    print(\"Multicloud dataset test accuracy: \")\n",
    "    y_pred = clf.predict(x_test_2)\n",
    "    print(metrics.classification_report(y_test_2, y_pred))\n",
    "    print(metrics.confusion_matrix(y_test_2, y_pred))\n",
    "    print('#' * 10 + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4afd537d-e81f-40c4-92f4-5ae572ec2364",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier()\n",
    "train_and_visualize(campus_dataset, clf)\n",
    "print(\"Azure dataset test accuracy: \")\n",
    "y_pred = clf.predict(azure_dataset[features])\n",
    "print(metrics.classification_report(azure_dataset[target_variable], y_pred))\n",
    "print(metrics.confusion_matrix(azure_dataset[target_variable], y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ca5571-1a5b-4175-9f02-d08716a78124",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(max_depth=2)\n",
    "clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cabc7dd1-8f04-4016-a391-31048627f2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(x_test)\n",
    "print(metrics.classification_report(azure_dataset[target_variable], y_pred))\n",
    "print(metrics.confusion_matrix(azure_dataset[target_variable], y_pred))\n",
    "\n",
    "fig = plt.figure(figsize=(25,20))\n",
    "plot_tree(clf, feature_names=x_train.columns, class_names=['benign', 'attack'], filled=True, max_depth=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06df6a9b-9ce9-43ac-b965-715c5b4df2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d729c8-a030-43c1-bc32-f9b5e6b7043b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(25,20))\n",
    "plot_tree(clf, feature_names=x_train.columns, class_names=['benign', 'attack'], filled=True, max_depth=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c857d00e-b681-43da-9e9d-9b17624eade5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Adding OOD example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ea1a52-c6aa-42c2-b66e-16f7491fe35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_ood_dataset(prefix: str):\n",
    "    dataset = pd.read_csv(f'{prefix}_dataset.csv')\n",
    "    dataset['Class'] = 0\n",
    "    dataset.loc[dataset['Src IP'].isin(pool_ips), 'Class'] = 1\n",
    "    ttl_data = pd.read_csv(f'{prefix}_ttl.csv')\n",
    "    dataset = dataset.merge(ttl_data, on=\"Flow ID\", how='left')\n",
    "    dataset = dataset.replace([np.inf, -np.inf], np.nan)\n",
    "    dataset = dataset.dropna(axis=0)\n",
    "    dataset = dataset.drop([\n",
    "        'Flow ID',\n",
    "        'Src IP',\n",
    "        'Dst IP',\n",
    "        'Timestamp', \n",
    "        'Protocol',    # always tcp\n",
    "        'Label',       # empty\n",
    "    ], axis=1)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4cdc5fb-31fc-4152-8592-2a86313830e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pool_ips = {\n",
    "    '169.231.10.199',\n",
    "    '169.231.210.93',\n",
    "    '169.231.8.190',\n",
    "    '169.231.123.195',\n",
    "}\n",
    "hydra_dataset = read_ood_dataset(\"ood\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add7d4e2-7755-427f-9d2d-8a0be6846d54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_hydra_test = hydra_dataset[features]\n",
    "y_hydra_test = hydra_dataset[target_variable]\n",
    "x_hydra_test = pd.DataFrame(StandardScaler().fit_transform(x_hydra_test), columns = x_hydra_test.columns)\n",
    "\n",
    "for clf in classifiers:\n",
    "    print(clf)\n",
    "    print(\"OOD test dataset accuracy: \")\n",
    "    y_pred = clf.predict(x_hydra_test)\n",
    "    print(metrics.classification_report(y_hydra_test, y_pred))\n",
    "    print(metrics.confusion_matrix(y_hydra_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c557a5b-fce3-4d54-a743-9001b091db45",
   "metadata": {},
   "source": [
    "## Dropping features test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca1ed6b-362e-4bc4-8852-300d215d26b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.drop(['TTL', 'Bwd Init Win Bytes'], axis=1)\n",
    "x_test = x_test.drop(['TTL', 'Bwd Init Win Bytes'], axis=1)\n",
    "x_test_2 = x_test_2.drop(['TTL', 'Bwd Init Win Bytes'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85337f71-463a-4240-88b9-f4df07b9498c",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [\n",
    "    MLPClassifier(),\n",
    "    GradientBoostingClassifier(),\n",
    "    RandomForestClassifier(max_depth=3)\n",
    "]\n",
    "for clf in classifiers:\n",
    "    print(clf)\n",
    "    clf.fit(x_train, y_train)\n",
    "    y_pred = clf.predict(x_train)\n",
    "    print(\"campus dataset training accuracy: \")\n",
    "    print(metrics.classification_report(y_train, y_pred))\n",
    "\n",
    "    print(\"Azure dataset test accuracy: \")\n",
    "    y_pred = clf.predict(x_test)\n",
    "    print(metrics.classification_report(y_test, y_pred))\n",
    "    print(metrics.confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    print(\"Multicloud dataset test accuracy: \")\n",
    "    y_pred = clf.predict(x_test_2)\n",
    "    print(metrics.classification_report(y_test_2, y_pred))\n",
    "    print(metrics.confusion_matrix(y_test_2, y_pred))\n",
    "    print('#' * 10 + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2649490a-a8b3-4673-a043-f612b026efc6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
